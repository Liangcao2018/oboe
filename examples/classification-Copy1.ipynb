{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification example to show how to use Oboe for training and testing, in the context of AutoML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "#Oboe modules; this will be simplified when Oboe becomes pip installable\n",
    "automl_path = '../automl/'\n",
    "sys.path.append(automl_path)\n",
    "from auto_learner import AutoLearner\n",
    "import util\n",
    "\n",
    "#import scikit-learn modules\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and split dataset into training and test folds\n",
    "data = load_iris()\n",
    "x = np.array(data['data'])\n",
    "y = np.array(data['target'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: a no-brainer use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the autolearner class\n",
    "m = AutoLearner(p_type='classification', runtime_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:132: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/cy438/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.04892344497607657\n",
      "elapsed time: 9.886321067810059\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))    \n",
    "print(\"elapsed time: {}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base learners': {'kSVM': [{'C': 4, 'coef0': 0, 'kernel': 'rbf'},\n",
       "   {'C': 2, 'coef0': 10, 'kernel': 'rbf'},\n",
       "   {'C': 8, 'coef0': 10, 'kernel': 'rbf'}]},\n",
       " 'ensemble method': 'greedy selection'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: build an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'random',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "#     'n_cores': N_CORES,\n",
    "    'build_ensemble': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_sample_candidates:[0, 1, 2, 3, 4, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "sufficient remaining time!\n",
      "n_cores:128\n",
      "to_sample:[ 69  19  17  22  63  52  54  45  41  64  18  27  39  26  70  43  99  74\n",
      "  90  66  29  95  55  58  98  47  60  20  23  77  14  11  75  78  28  25\n",
      "  35  89  65  16   2  36  51  44  85  31  73  79  61  59  91  32  48  81\n",
      "  57  42  71  15  82  94  92  86  76   3  88   1  40  13   0  68  38  10\n",
      "  96  97  87  80  34 100  83  53  67  12  30  93  33  84   4  21  49  72\n",
      "  56  46  37  50  62  24]\n",
      "96\n",
      "to_sample_candidates:[5, 6, 7, 8, 9]\n",
      "sufficient remaining time!\n",
      "n_cores:128\n",
      "to_sample:[5 9 7 8 6]\n",
      "5\n",
      "to_sample_candidates:[]\n",
      "to_sample:[19]\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6eeb8b8b6444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit autolearner on training set and record runtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/auto_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, verbose)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0mdoubling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/auto_learner.py\u001b[0m in \u001b[0;36mdoubling\u001b[0;34m()\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_ensemble\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/auto_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, x_train, y_train, rank, runtime_limit)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nFitting ensemble of max. size {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_learners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# ensemble selection and fitting in the remaining time budget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_learners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, runtime_limit, fitted_base_learners)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mruntime_limit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mMaximum\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mallocated\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_base_learners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_base_learners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;31m# TODO: parallelize training over base learners\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_learners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/model.py\u001b[0m in \u001b[0;36mselect_base_learners\u001b[0;34m(self, y_train, fitted_base_learners)\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_learners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_learners\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_errors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Ensemble size must be greater than zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c06ef0ec5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use the fitted autolearner for prediction on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prediction error: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"elapsed time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"individual accuracies of selected models: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/auto_learner.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x_test)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredicted\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oboe/automl/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x_test)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredicted\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \"\"\"\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_learners\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ensemble size must be greater than zero.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mbase_learner_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Ensemble size must be greater than zero."
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))\n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"individual accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'greedy selection',\n",
       " 'base learners': {'KNN': [{'n_neighbors': 13, 'p': 1},\n",
       "   {'n_neighbors': 13, 'p': 2},\n",
       "   {'n_neighbors': 15, 'p': 2}]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: just select a collection of promising models without building an ensemble afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:132: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:132: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:132: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:132: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n"
     ]
    }
   ],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 8.05806303024292\n",
      "accuracies of selected models: [0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.0, 0.025000000000000022, 0.025000000000000022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.0, 0.025000000000000022, 0.0, 0.0, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.0, 0.0, 0.04999999999999999, 0.025000000000000022, 0.025000000000000022, 0.0, 0.0, 0.04999999999999999, 0.04999999999999999, 0.04999999999999999, 0.04999999999999999, 0.04999999999999999, 0.0, 0.025000000000000022, 0.04999999999999999, 0.0, 0.04999999999999999, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.04999999999999999, 0.025000000000000022, 0.025000000000000022, 0.025000000000000022, 0.17499999999999996, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    " \n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not have a single accuracy value here if we do not build an ensemble, instead, we just have a collection of fitted models with individual accuracies reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': [{'n_neighbors': 1, 'p': 1},\n",
       "  {'n_neighbors': 1, 'p': 1},\n",
       "  {'n_neighbors': 3, 'p': 1},\n",
       "  {'n_neighbors': 1, 'p': 2},\n",
       "  {'n_neighbors': 3, 'p': 2},\n",
       "  {'n_neighbors': 5, 'p': 1},\n",
       "  {'n_neighbors': 7, 'p': 1},\n",
       "  {'n_neighbors': 5, 'p': 2},\n",
       "  {'n_neighbors': 7, 'p': 2},\n",
       "  {'n_neighbors': 9, 'p': 1},\n",
       "  {'n_neighbors': 9, 'p': 2},\n",
       "  {'n_neighbors': 11, 'p': 1},\n",
       "  {'n_neighbors': 13, 'p': 1},\n",
       "  {'n_neighbors': 11, 'p': 2},\n",
       "  {'n_neighbors': 15, 'p': 1},\n",
       "  {'n_neighbors': 13, 'p': 2},\n",
       "  {'n_neighbors': 15, 'p': 2}],\n",
       " 'ExtraTrees': [{'min_samples_split': 4, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 4, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 8, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 8, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 16, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 16, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 32, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 64, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 64, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 128, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 128, 'criterion': 'entropy'}],\n",
       " 'RF': [{'min_samples_split': 2, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 4, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 4, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 8, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 8, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 16, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 16, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 32, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 64, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 64, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1024, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1024, 'criterion': 'gini'}],\n",
       " 'AB': [{'n_estimators': 100, 'learning_rate': 1.5},\n",
       "  {'n_estimators': 50, 'learning_rate': 1.5},\n",
       "  {'n_estimators': 100, 'learning_rate': 1},\n",
       "  {'n_estimators': 50, 'learning_rate': 1},\n",
       "  {'n_estimators': 100, 'learning_rate': 2}],\n",
       " 'DT': [{'min_samples_split': 0.0001},\n",
       "  {'min_samples_split': 1e-05},\n",
       "  {'min_samples_split': 2},\n",
       "  {'min_samples_split': 0.001},\n",
       "  {'min_samples_split': 4},\n",
       "  {'min_samples_split': 8},\n",
       "  {'min_samples_split': 0.01},\n",
       "  {'min_samples_split': 16},\n",
       "  {'min_samples_split': 32},\n",
       "  {'min_samples_split': 64},\n",
       "  {'min_samples_split': 128},\n",
       "  {'min_samples_split': 1024}],\n",
       " 'GNB': [{}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
