{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a classification example to show how to use Oboe for training and testing, in the context of AutoML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "#Oboe modules; this will be simplified when Oboe becomes pip installable\n",
    "automl_path = '../automl/'\n",
    "sys.path.append(automl_path)\n",
    "from auto_learner import AutoLearner\n",
    "import util\n",
    "\n",
    "#import scikit-learn modules\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and split dataset into training and test folds\n",
    "data = load_iris()\n",
    "x = np.array(data['data'])\n",
    "y = np.array(data['target'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: a no-brainer use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the autolearner class\n",
    "# m = AutoLearner(p_type='classification', runtime_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit autolearner on training set and record runtime\n",
    "# start = time.time()\n",
    "# m.fit(x_train, y_train)\n",
    "# elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use the fitted autolearner for prediction on test set\n",
    "# y_predicted = m.predict(x_test)\n",
    "# print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))    \n",
    "# print(\"elapsed time: {}\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get names of the selected machine learning models\n",
    "# m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: build an ensemble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': True,\n",
    "    'coca': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:136: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:136: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n"
     ]
    }
   ],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error: 0.03670634920634921\n",
      "elapsed time: 344.23552417755127\n",
      "individual accuracies of selected models: [0.03670634920634921, 0.03670634920634921, 0.03670634920634921]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    "print(\"prediction error: {}\".format(util.error(y_test, y_predicted, 'classification')))\n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"individual accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble method': 'greedy selection',\n",
       " 'base learners': {'AB': [{'n_estimators': 50, 'learning_rate': 2.5},\n",
       "   {'n_estimators': 50, 'learning_rate': 2.5},\n",
       "   {'n_estimators': 50, 'learning_rate': 1}]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: just select a collection of promising models without building an ensemble afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental settings\n",
    "VERBOSE = False #whether to print out information indicating current fitting progress\n",
    "N_CORES = 1 #number of cores\n",
    "RUNTIME_BUDGET = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: limit the types of algorithms\n",
    "s = ['AB', 'ExtraTrees', 'GNB', 'KNN', 'RF', 'DT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autolearner arguments\n",
    "autolearner_kwargs = {\n",
    "    'p_type': 'classification',\n",
    "    'runtime_limit': RUNTIME_BUDGET,\n",
    "    'verbose': VERBOSE,\n",
    "    'selection_method': 'min_variance',\n",
    "    'algorithms': s,\n",
    "    'stacking_alg': 'greedy',\n",
    "    'n_cores': N_CORES,\n",
    "    'build_ensemble': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the autolearner class\n",
    "m = AutoLearner(**autolearner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:136: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:136: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:136: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n",
      "../automl/convex_opt.py:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return -1 * sign * log_det\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:1817: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "../automl/auto_learner.py:136: RuntimeWarning: invalid value encountered in greater\n",
      "  to_sample = valid[np.where(v_opt > 0.9)[0]]\n"
     ]
    }
   ],
   "source": [
    "# fit autolearner on training set and record runtime\n",
    "start = time.time()\n",
    "m.fit(x_train, y_train)\n",
    "elapsed_time = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 7.7686731815338135\n",
      "accuracies of selected models: [0.01835317460317461, 0.01835317460317461, 0.01835317460317461, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.01835317460317461, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.01835317460317461, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.055059523809523815, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.055059523809523815, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.055059523809523815, 0.03670634920634921, 0.055059523809523815, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.03670634920634921, 0.055059523809523815, 0.055059523809523815, 0.03670634920634921, 0.055059523809523815, 0.055059523809523815, 0.055059523809523815, 0.03670634920634921, 0.055059523809523815, 0.055059523809523815, 0.03670634920634921, 0.055059523809523815, 0.03670634920634921, 0.055059523809523815, 0.055059523809523815, 0.055059523809523815, 0.055059523809523815, 0.29365079365079366, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# use the fitted autolearner for prediction on test set\n",
    "y_predicted = m.predict(x_test)\n",
    " \n",
    "print(\"elapsed time: {}\".format(elapsed_time))\n",
    "print(\"accuracies of selected models: {}\".format(m.get_model_accuracy(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do not have a single accuracy value here if we do not build an ensemble, instead, we just have a collection of fitted models with individual accuracies reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': [{'n_neighbors': 1, 'p': 1},\n",
       "  {'n_neighbors': 1, 'p': 1},\n",
       "  {'n_neighbors': 1, 'p': 2},\n",
       "  {'n_neighbors': 3, 'p': 1},\n",
       "  {'n_neighbors': 3, 'p': 2},\n",
       "  {'n_neighbors': 5, 'p': 1},\n",
       "  {'n_neighbors': 5, 'p': 2},\n",
       "  {'n_neighbors': 7, 'p': 1},\n",
       "  {'n_neighbors': 7, 'p': 2},\n",
       "  {'n_neighbors': 9, 'p': 1},\n",
       "  {'n_neighbors': 9, 'p': 2},\n",
       "  {'n_neighbors': 11, 'p': 1},\n",
       "  {'n_neighbors': 13, 'p': 1},\n",
       "  {'n_neighbors': 11, 'p': 2},\n",
       "  {'n_neighbors': 15, 'p': 1},\n",
       "  {'n_neighbors': 13, 'p': 2},\n",
       "  {'n_neighbors': 15, 'p': 2}],\n",
       " 'ExtraTrees': [{'min_samples_split': 0.0001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 2, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 4, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 4, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 8, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 8, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 16, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 16, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 32, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 64, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 64, 'criterion': 'gini'}],\n",
       " 'RF': [{'min_samples_split': 1e-05, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 2, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 4, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.0001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 1e-05, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 2, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.001, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 4, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 8, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 8, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.01, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 16, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 16, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 32, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 32, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'entropy'},\n",
       "  {'min_samples_split': 0.1, 'criterion': 'gini'},\n",
       "  {'min_samples_split': 64, 'criterion': 'gini'}],\n",
       " 'DT': [{'min_samples_split': 0.0001},\n",
       "  {'min_samples_split': 2},\n",
       "  {'min_samples_split': 1e-05},\n",
       "  {'min_samples_split': 0.001},\n",
       "  {'min_samples_split': 4},\n",
       "  {'min_samples_split': 8},\n",
       "  {'min_samples_split': 0.01},\n",
       "  {'min_samples_split': 16},\n",
       "  {'min_samples_split': 32},\n",
       "  {'min_samples_split': 64},\n",
       "  {'min_samples_split': 128},\n",
       "  {'min_samples_split': 1024},\n",
       "  {'min_samples_split': 512},\n",
       "  {'min_samples_split': 256}],\n",
       " 'AB': [{'n_estimators': 100, 'learning_rate': 1.5},\n",
       "  {'n_estimators': 50, 'learning_rate': 1.5},\n",
       "  {'n_estimators': 100, 'learning_rate': 1},\n",
       "  {'n_estimators': 100, 'learning_rate': 2},\n",
       "  {'n_estimators': 50, 'learning_rate': 1},\n",
       "  {'n_estimators': 50, 'learning_rate': 2}],\n",
       " 'GNB': [{}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get names of the selected machine learning models\n",
    "m.get_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
